{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import detectron2\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Dataset\n",
    "try:\n",
    "    register_coco_instances('coco_trash_train', {}, '../../dataset/train.json', '../../dataset/')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    register_coco_instances('coco_trash_test', {}, '../../dataset/test.json', '../../dataset/')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "MetadataCatalog.get('coco_trash_train').thing_classes = [\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \n",
    "                                                         \"Glass\", \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 불러오기\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file('COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 수정하기\n",
    "cfg.DATASETS.TRAIN = ('coco_trash_train',)\n",
    "cfg.DATASETS.TEST = ('coco_trash_test',)\n",
    "\n",
    "cfg.DATALOADER.NUM_WOREKRS = 2\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url('COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml')\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "cfg.SOLVER.MAX_ITER = 15000\n",
    "cfg.SOLVER.STEPS = (8000,12000)\n",
    "cfg.SOLVER.GAMMA = 0.005\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 3000\n",
    "\n",
    "cfg.OUTPUT_DIR = './output'\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = DatasetCatalog.get('coco_trash_train')\n",
    "test_ds = DatasetCatalog.get('coco_trash_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = MetadataCatalog.get('coco_trash_train')\n",
    "# metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 리스트 초기화\n",
    "general_trash_list, paper_list, paper_pack_list, metal_list = [], [], [], []\n",
    "glass_list, plastic_list, styrofoam_list, plastic_bag_list = [], [], [], []\n",
    "battery_list, clothing_list = [], []\n",
    "\n",
    "# 클래스별 카운터 초기화\n",
    "num_general_trash, num_paper, num_paper_pack, num_metal = 0, 0, 0, 0\n",
    "num_glass, num_plastic, num_styrofoam, num_plastic_bag = 0, 0, 0, 0\n",
    "num_battery, num_clothing = 0, 0\n",
    "\n",
    "# 데이터셋 순회\n",
    "for i in range(len(train_ds)):\n",
    "    category_id = train_ds[i][\"annotations\"][0][\"category_id\"]\n",
    "    if category_id == 0:\n",
    "        general_trash_list.append(train_ds[i])\n",
    "        num_general_trash += 1\n",
    "    elif category_id == 1:\n",
    "        paper_list.append(train_ds[i])\n",
    "        num_paper += 1\n",
    "    elif category_id == 2:\n",
    "        paper_pack_list.append(train_ds[i])\n",
    "        num_paper_pack += 1\n",
    "    elif category_id == 3:\n",
    "        metal_list.append(train_ds[i])\n",
    "        num_metal += 1\n",
    "    elif category_id == 4:\n",
    "        glass_list.append(train_ds[i])\n",
    "        num_glass += 1\n",
    "    elif category_id == 5:\n",
    "        plastic_list.append(train_ds[i])\n",
    "        num_plastic += 1\n",
    "    elif category_id == 6:\n",
    "        styrofoam_list.append(train_ds[i])\n",
    "        num_styrofoam += 1\n",
    "    elif category_id == 7:\n",
    "        plastic_bag_list.append(train_ds[i])\n",
    "        num_plastic_bag += 1\n",
    "    elif category_id == 8:\n",
    "        battery_list.append(train_ds[i])\n",
    "        num_battery += 1\n",
    "    elif category_id == 9:\n",
    "        clothing_list.append(train_ds[i])\n",
    "        num_clothing += 1\n",
    "\n",
    "# 클래스 리스트와 카운터 리스트 생성\n",
    "class_list = [\n",
    "    general_trash_list, paper_list, paper_pack_list, metal_list,\n",
    "    glass_list, plastic_list, styrofoam_list, plastic_bag_list,\n",
    "    battery_list, clothing_list\n",
    "]\n",
    "num = [\n",
    "    num_general_trash, num_paper, num_paper_pack, num_metal,\n",
    "    num_glass, num_plastic, num_styrofoam, num_plastic_bag,\n",
    "    num_battery, num_clothing\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ds2Numpy_arr(annotations):\n",
    "    gt_bboxes = []\n",
    "    classes = []\n",
    "    \n",
    "    for i in range(len(annotations)):\n",
    "        # Bounding box를 그대로 사용\n",
    "        gt_bboxes.append(annotations[i][\"bbox\"])\n",
    "        \n",
    "        # Category ID 추가 (클래스 정보)\n",
    "        classes.append(annotations[i][\"category_id\"])\n",
    "    \n",
    "    return gt_bboxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original image's size: rotate + centrer crop\n",
    "ROTATED_CENTRER_CROP = A.Compose([\n",
    "                        A.Rotate(limit=175, border_mode=1, p=1.0),\n",
    "                        # A.CenterCrop(height=325, width=440, p=1.0),  #(325/440 = 65/85 = 520/704)\n",
    "                        A.CenterCrop(height=400, width=400, p=1.0), \n",
    "                        A.HorizontalFlip(p=0.5),\n",
    "                        A.VerticalFlip(p=0.5),\n",
    "                        ], bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"bbox_classes\"])) \n",
    "\n",
    "# original image's size: transpose + random crop\n",
    "TRANSPOSE_RANDOM_CROP = A.Compose([\n",
    "                        A.Transpose(p=1.0),\n",
    "                        # A.RandomCrop(height=325, width=440, p=1.0),  #(325/440 = 65/85 = 520/704)\n",
    "                        A.RandomCrop(height=400, width=400, p=1.0), \n",
    "                        A.HorizontalFlip(p=0.5),\n",
    "                        A.VerticalFlip(p=0.5),\n",
    "                        ], bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"bbox_classes\"])) \n",
    "\n",
    "def is_tiny_box(height, width, min_area=30):\n",
    "    return True if height * width < min_area else False\n",
    "\n",
    "\n",
    "def create_a_mosaic_set(image_list, xc, yc, H_mosaic_img, W_mosaic_img):\n",
    "    mosaic_image = np.full((H_mosaic_img, W_mosaic_img, 3), 1, dtype=np.uint8) \n",
    "    mosaic_bboxes, mosaic_bbox_classes = [], []        \n",
    "\n",
    "    for i, image_set in enumerate(image_list):\n",
    "        shape = image_set[\"image\"].shape\n",
    "        if i == 0: #top-left\n",
    "            mosaic_image[0:yc, 0:xc, :] = image_set[\"image\"]\n",
    "            for box, bbox_class in zip(image_set[\"bboxes\"], image_set[\"bbox_classes\"]):\n",
    "                box = list(box)\n",
    "                # \"pascal_voc\" to \"coco\"\n",
    "                box[2] -= box[0]\n",
    "                box[3] -= box[1]\n",
    "                assert box[0] < xc and box[1] < yc and box[2] <= xc and box[3] <= yc, f\"sub-image shape: {shape} || box: {box}\"\n",
    "                if is_tiny_box(*box[2:]):\n",
    "                    continue\n",
    "                mosaic_bboxes.append(box)\n",
    "                mosaic_bbox_classes.append(bbox_class)\n",
    "        elif i == 1: #top-right\n",
    "            mosaic_image[0:yc, xc:, :] = image_set[\"image\"]\n",
    "            for box, bbox_class in zip(image_set[\"bboxes\"], image_set[\"bbox_classes\"]):\n",
    "                box = list(box)\n",
    "                # \"pascal_voc\" to \"coco\"\n",
    "                box[2] -= box[0]\n",
    "                box[3] -= box[1]\n",
    "                if is_tiny_box(*box[2:]):\n",
    "                    continue\n",
    "                assert box[0] < W_mosaic_img - xc and box[1] < yc and box[2] <= W_mosaic_img - xc and box[3] <= yc, f\"sub-image shape: {shape} || box: {box}\"\n",
    "                box[0] += xc\n",
    "                mosaic_bboxes.append(box)\n",
    "                mosaic_bbox_classes.append(bbox_class)\n",
    "        elif i == 2: #bottom-left\n",
    "            mosaic_image[yc:, 0:xc, :] = image_set[\"image\"]\n",
    "            for box, bbox_class in zip(image_set[\"bboxes\"], image_set[\"bbox_classes\"]):\n",
    "                box = list(box)\n",
    "                # \"pascal_voc\" to \"coco\"\n",
    "                box[2] -= box[0]\n",
    "                box[3] -= box[1]\n",
    "                assert box[0] < xc and box[1] < H_mosaic_img - yc and box[2] <= xc and box[3] <= H_mosaic_img - yc, f\"sub-image shape: {shape} || box: {box}\"\n",
    "                if is_tiny_box(*box[2:]):\n",
    "                    continue\n",
    "                box[1] += yc\n",
    "                mosaic_bboxes.append(box)\n",
    "                mosaic_bbox_classes.append(bbox_class)\n",
    "        else:  # bottom-right\n",
    "            mosaic_image[yc:, xc:, :] = image_set[\"image\"]\n",
    "            for box, bbox_class in zip(image_set[\"bboxes\"], image_set[\"bbox_classes\"]):\n",
    "                box = list(box)\n",
    "                # \"pascal_voc\" to \"coco\"\n",
    "                box[2] -= box[0]\n",
    "                box[3] -= box[1]\n",
    "                if is_tiny_box(*box[2:]):\n",
    "                    continue\n",
    "                assert box[0] < W_mosaic_img - xc and box[1] < H_mosaic_img - yc and box[2] <= W_mosaic_img - xc and box[3] <= H_mosaic_img - yc, f\"sub-image shape: {shape} || box: {box}\"\n",
    "                box[0] += xc\n",
    "                box[1] += yc\n",
    "                mosaic_bboxes.append(box)\n",
    "                mosaic_bbox_classes.append(bbox_class)\n",
    "\n",
    "    return mosaic_image, mosaic_bboxes, mosaic_bbox_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapper - input data를 어떤 형식으로 return할지 (따라서 augmnentation 등 데이터 전처리 포함 됨)\n",
    "import detectron2.data.transforms as T\n",
    "\n",
    "def AlbumentationsMapper(dataset_dict):\n",
    "    # READ IMAGE 1:\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)\n",
    "    image_1 = utils.read_image(dataset_dict[\"file_name\"])\n",
    "    \n",
    "    gt_bboxes_1, classes_1 = train_ds2Numpy_arr(dataset_dict[\"annotations\"])  # 마스크 관련 제거\n",
    "    # print('classes_1 = ', classes_1)\n",
    "    if random.random() < 0.6:\n",
    "        #FINAL\n",
    "        # n_height = np.random.choice([640, 672, 704, 736, 768, 800])\n",
    "        # n_width = int((n_height * 704 / 520) + 0.5)\n",
    "\n",
    "        n_height = 1024\n",
    "        n_width = 1024\n",
    "\n",
    "        FINAL = A.Compose([\n",
    "                            A.HorizontalFlip(p=0.5),\n",
    "                            A.VerticalFlip(p=0.5),\n",
    "                            A.Resize(height=n_height, width=n_width, p=1.0),\n",
    "                            ToTensorV2(p=1.0),\n",
    "                            ], bbox_params=A.BboxParams(format=\"coco\", label_fields=[\"bbox_classes\"]))\n",
    "        transformed = FINAL(image=image_1, bboxes=gt_bboxes_1, bbox_classes=classes_1)\n",
    "        transformed_image, transformed_bboxes, transformed_bbox_classes = \\\n",
    "        transformed[\"image\"], transformed[\"bboxes\"], transformed[\"bbox_classes\"]\n",
    "    else: \n",
    "        # dataset_dict_2, dataset_dict_3, dataset_dict_4 of 3 images with same cell type. \n",
    "        cell_type = classes_1[0]\n",
    "        listOfdict = class_list[cell_type]\n",
    "        num_dict = num[cell_type]\n",
    "        dataset_dict_2 = copy.deepcopy(listOfdict[random.randint(0, num_dict - 1)])\n",
    "        dataset_dict_3 = copy.deepcopy(listOfdict[random.randint(0, num_dict - 1)])\n",
    "        dataset_dict_4 = copy.deepcopy(listOfdict[random.randint(0, num_dict - 1)])\n",
    "        del listOfdict\n",
    "        \n",
    "        # READ 3 IMAGES + CHANGE BBOX FORMAT FROM \"coco\" TO \"pascal_voc\":\n",
    "        # IMAGE 1:\n",
    "        for idx, box in enumerate(gt_bboxes_1):\n",
    "            gt_bboxes_1[idx][2] += box[0]\n",
    "            gt_bboxes_1[idx][3] += box[1]\n",
    "        # IMAGE 2:\n",
    "        image_2 = utils.read_image(dataset_dict_2[\"file_name\"])\n",
    "        gt_bboxes_2, classes_2 = train_ds2Numpy_arr(dataset_dict_2[\"annotations\"])\n",
    "        for idx, box in enumerate(gt_bboxes_2):\n",
    "            gt_bboxes_2[idx][2] += box[0]\n",
    "            gt_bboxes_2[idx][3] += box[1]\n",
    "        # IMAGE 3:\n",
    "        image_3 = utils.read_image(dataset_dict_3[\"file_name\"])\n",
    "        gt_bboxes_3, classes_3 = train_ds2Numpy_arr(dataset_dict_3[\"annotations\"])\n",
    "        for idx, box in enumerate(gt_bboxes_3):\n",
    "            gt_bboxes_3[idx][2] += box[0]\n",
    "            gt_bboxes_3[idx][3] += box[1]\n",
    "        # IMAGE 4:\n",
    "        image_4 = utils.read_image(dataset_dict_4[\"file_name\"])\n",
    "        gt_bboxes_4, classes_4 = train_ds2Numpy_arr(dataset_dict_4[\"annotations\"])\n",
    "        for idx, box in enumerate(gt_bboxes_4):\n",
    "            gt_bboxes_4[idx][2] += box[0]\n",
    "            gt_bboxes_4[idx][3] += box[1]\n",
    "\n",
    "        # CUSTOMED_MOSAIC: 4 images (height=400, width=400) & \"rotate + centrer crop\" or \"transpose + random crop\" -> height=800, width=800\n",
    "        if random.random() < 0.5: \n",
    "            image_list = []\n",
    "            # IMAGE 1:\n",
    "            transformed = ROTATED_CENTRER_CROP(image=image_1, bboxes=gt_bboxes_1, bbox_classes=classes_1)\n",
    "            image_list.append({\"image\": transformed[\"image\"], \"bboxes\": transformed[\"bboxes\"], \"bbox_classes\": transformed[\"bbox_classes\"]})\n",
    "            # IMAGE 2:\n",
    "            transformed = ROTATED_CENTRER_CROP(image=image_2, bboxes=gt_bboxes_2, bbox_classes=classes_2)\n",
    "            image_list.append({\"image\": transformed[\"image\"], \"bboxes\": transformed[\"bboxes\"], \"bbox_classes\": transformed[\"bbox_classes\"]})\n",
    "            # IMAGE 3:\n",
    "            transformed = TRANSPOSE_RANDOM_CROP(image=image_3, bboxes=gt_bboxes_3, bbox_classes=classes_3)\n",
    "            image_list.append({\"image\": transformed[\"image\"], \"bboxes\": transformed[\"bboxes\"], \"bbox_classes\": transformed[\"bbox_classes\"]})\n",
    "            # IMAGE 4:\n",
    "            transformed = TRANSPOSE_RANDOM_CROP(image=image_4, bboxes=gt_bboxes_4, bbox_classes=classes_4)\n",
    "            image_list.append({\"image\": transformed[\"image\"], \"bboxes\": transformed[\"bboxes\"], \"bbox_classes\": transformed[\"bbox_classes\"]})\n",
    "            # CUSTOMED MOSAIC SET:\n",
    "            random.shuffle(image_list)\n",
    "            inf = {\"xc\": 400, \"yc\": 400, \"H_mosaic_img\": 800, \"W_mosaic_img\": 800}\n",
    "            cus_mosaic_image, cus_mosaic_bboxes, cus_mosaic_bbox_classes = create_a_mosaic_set(image_list, **inf)\n",
    "\n",
    "            # FINAL:\n",
    "            # n_height = np.random.choice([672, 704, 736, 768, 800])\n",
    "            # n_width = int((n_height * 704 / 520) + 0.5)\n",
    "\n",
    "            n_height = 1024\n",
    "            n_width = 1024\n",
    "\n",
    "            FINAL = A.Compose([\n",
    "                                A.Resize(height=n_height, width=n_width, p=1.0),\n",
    "                                ToTensorV2(p=1.0),\n",
    "                                ], bbox_params=A.BboxParams(format=\"coco\", label_fields=[\"bbox_classes\"]))\n",
    "            transformed = FINAL(image=cus_mosaic_image, bboxes=cus_mosaic_bboxes, bbox_classes=cus_mosaic_bbox_classes)\n",
    "            transformed_image, transformed_bboxes, transformed_bbox_classes = \\\n",
    "            transformed[\"image\"], transformed[\"bboxes\"], transformed[\"bbox_classes\"]\n",
    "            \n",
    "        # MOSAIC: 4 images & \"random height and width\" + \"random crop\" -> height=800, width=800\n",
    "        else:\n",
    "            image_list = []\n",
    "            H_mosaic = 800\n",
    "            W_mosaic = 800\n",
    "            # xc = int(random.uniform(400, 624)) # W_mosaic - 400\n",
    "            # yc = int(random.uniform(400, 624)) # H_mosaic - 400\n",
    "            xc = 400\n",
    "            yc = 400\n",
    "            # IMAGE 1: top-left\n",
    "            RANDOM_CROP = A.Compose([\n",
    "                                A.RandomCrop(height=yc, width=xc, p=1),\n",
    "                                A.HorizontalFlip(p=0.5),\n",
    "                                A.VerticalFlip(p=0.5),\n",
    "                                ], bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"bbox_classes\"]))\n",
    "            transformed = RANDOM_CROP(image=image_1, bboxes=gt_bboxes_1, bbox_classes=classes_1)\n",
    "            image_list.append({\"image\": transformed[\"image\"], \"bboxes\": transformed[\"bboxes\"], \"bbox_classes\": transformed[\"bbox_classes\"]})\n",
    "            # IMAGE 2: top-right\n",
    "            RANDOM_CROP = A.Compose([\n",
    "                                A.RandomCrop(height=yc, width=W_mosaic-xc, p=1),\n",
    "                                A.HorizontalFlip(p=0.5),\n",
    "                                A.VerticalFlip(p=0.5),\n",
    "                                ], bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"bbox_classes\"]))\n",
    "            transformed = RANDOM_CROP(image=image_2, bboxes=gt_bboxes_2, bbox_classes=classes_2)\n",
    "            image_list.append({\"image\": transformed[\"image\"], \"bboxes\": transformed[\"bboxes\"], \"bbox_classes\": transformed[\"bbox_classes\"]})\n",
    "            # IMAGE 3: bottom-left\n",
    "            RANDOM_CROP = A.Compose([\n",
    "                                A.RandomCrop(height=H_mosaic-yc, width=xc, p=1),\n",
    "                                A.HorizontalFlip(p=0.5),\n",
    "                                A.VerticalFlip(p=0.5),\n",
    "                                ], bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"bbox_classes\"]))\n",
    "            transformed = RANDOM_CROP(image=image_3, bboxes=gt_bboxes_3, bbox_classes=classes_3)\n",
    "            image_list.append({\"image\": transformed[\"image\"], \"bboxes\": transformed[\"bboxes\"], \"bbox_classes\": transformed[\"bbox_classes\"]})\n",
    "            # IMAGE 4: bottom-right\n",
    "            RANDOM_CROP = A.Compose([\n",
    "                                A.RandomCrop(height=H_mosaic-yc, width=W_mosaic-xc, p=1),\n",
    "                                A.HorizontalFlip(p=0.5),\n",
    "                                A.VerticalFlip(p=0.5),\n",
    "                                ], bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"bbox_classes\"]))\n",
    "            transformed = RANDOM_CROP(image=image_4, bboxes=gt_bboxes_4, bbox_classes=classes_4)\n",
    "            image_list.append({\"image\": transformed[\"image\"], \"bboxes\": transformed[\"bboxes\"], \"bbox_classes\": transformed[\"bbox_classes\"]})\n",
    "            # MOSAIC SET:\n",
    "            inf = {\"xc\": xc, \"yc\": yc, \"H_mosaic_img\": 800, \"W_mosaic_img\": 800}\n",
    "            mosaic_image, mosaic_bboxes, mosaic_bbox_classes = create_a_mosaic_set(image_list, **inf)\n",
    "\n",
    "            # FINAL:\n",
    "            # n_height = np.random.choice([736, 768, 800])\n",
    "            # n_width = int((n_height * 704 / 520) + 0.5)\n",
    "\n",
    "            n_height = 1024\n",
    "            n_width = 1024\n",
    "\n",
    "            FINAL = A.Compose([\n",
    "                                A.Resize(height=n_height, width=n_width, p=1.0),\n",
    "                                ToTensorV2(p=1.0),\n",
    "                                ], bbox_params=A.BboxParams(format=\"coco\", label_fields=[\"bbox_classes\"]))\n",
    "            transformed = FINAL(image=mosaic_image, bboxes=mosaic_bboxes, bbox_classes=mosaic_bbox_classes)\n",
    "            transformed_image, transformed_bboxes, transformed_bbox_classes = \\\n",
    "            transformed[\"image\"], transformed[\"bboxes\"], transformed[\"bbox_classes\"]\n",
    "    \n",
    "    annos = []  # 바운딩 박스와 클래스 정보를 인스턴스 어노테이션으로 변환\n",
    "    for gt_box, gt_class in zip(transformed_bboxes, transformed_bbox_classes):\n",
    "        instance_annotations = {'bbox': gt_box, 'bbox_mode': dataset_dict[\"annotations\"][0][\"bbox_mode\"], 'category_id': gt_class}\n",
    "        annos.append(instance_annotations)\n",
    "    \n",
    "    final_dataset_dict = {'image': transformed_image, 'height': n_height, 'width': n_width} \n",
    "    \n",
    "    instances = utils.annotations_to_instances(annos, image_size=(n_height, n_width))\n",
    "    final_dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
    "\n",
    "    return final_dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer - DefaultTrainer를 상속\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg, sampler=None):\n",
    "        return build_detection_train_loader(\n",
    "        cfg, mapper = AlbumentationsMapper, sampler = sampler\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs('./output_eval', exist_ok = True)\n",
    "            output_folder = './output_eval'\n",
    "            \n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok = True)\n",
    "\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
